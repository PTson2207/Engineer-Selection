{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0812c04e35dc2017d178d326aa5395980bc18abc67fe5fd6ae6b58e824e490792",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Ut Luom\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Ut Luom\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Ut Luom\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Ut Luom\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from Selection import filter_method as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "data = pd.DataFrame(np.c_[data['data'], data['target']],\n",
    "                  columns= np.append(data['feature_names'], ['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890     0.0  \n",
       "1          0.2750                  0.08902     0.0  \n",
       "2          0.3613                  0.08758     0.0  \n",
       "3          0.6638                  0.17300     0.0  \n",
       "4          0.2364                  0.07678     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>...</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('target', axis=1), data.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "source": [
    "# Correlation method\n",
    "loại bỏ các tính năng có độ tương quan cao với nhau"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       feature1       feature2  correlation\n0  mean texture  worst texture     0.909718 \n\n              feature1              feature2  correlation\n2  mean concave points  worst concave points     0.910680\n5  mean concave points        mean concavity     0.914671 \n\n           feature1      feature2  correlation\n6   perimeter error    area error     0.937271\n29  perimeter error  radius error     0.973560 \n\n      feature1         feature2  correlation\n8   worst area      mean radius     0.941849\n11  worst area   mean perimeter     0.943283\n17  worst area        mean area     0.959723\n30  worst area  worst perimeter     0.976979\n32  worst area     worst radius     0.983458 \n\n"
     ]
    }
   ],
   "source": [
    "corr = ft.corr_feature_detect(data=X_train, threshold=0.9)\n",
    "for i in corr:\n",
    "    print(i, '\\n')"
   ]
  },
  {
   "source": [
    "# Variance method\n",
    "loại bỏ các tính năng hiển thị cùng một giá trị cho phần lớn/ tất cả các quan sát"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0  biến được tìm thấy gần như không đổi\n"
     ]
    }
   ],
   "source": [
    "quasi_constant_feature = ft.constant_feature_detect(data=X_train, threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0    0.914286\n",
       "0.0    0.079121\n",
       "2.0    0.006593\n",
       "Name: dummy, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# tạo một biến giả để thử với phương pháp trên\n",
    "X_train['dummy'] = np.floor(X_train['worst smoothness']*10)\n",
    "X_train.dummy.value_counts()/ np.float(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1  biến được tìm thấy gần như không đổi\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['dummy']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "quasi_constant_feature = ft.constant_feature_detect(data=X_train, threshold=0.9)\n",
    "quasi_constant_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop values\n",
    "X_train.drop(labels=quasi_constant_feature, axis=1, inplace=True)"
   ]
  },
  {
   "source": [
    "# Sắp xếp feature dựa trên AUC và MSE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "worst area                 0.917458\nworst concave points       0.905830\nworst radius               0.889125\nworst perimeter            0.878808\narea error                 0.875860\nmean radius                0.865870\nmean concave points        0.829021\nmean concavity             0.818867\nmean perimeter             0.799869\nmean area                  0.797085\nworst concavity            0.786276\nradius error               0.765640\nperimeter error            0.764330\nworst compactness          0.719784\nmean compactness           0.714216\nworst fractal dimension    0.641828\nmean texture               0.634294\nconcave points error       0.619227\nmean symmetry              0.611202\nconcavity error            0.601539\nworst texture              0.585653\nmean smoothness            0.570259\nmean fractal dimension     0.555519\nworst smoothness           0.549132\ncompactness error          0.533082\nsmoothness error           0.530789\nfractal dimension error    0.529152\ntexture error              0.519325\nworst symmetry             0.511300\nsymmetry error             0.460039\ndtype: float64\n8 trong 30 feature được giữ lại\nmean radius             0.865870\nmean concavity          0.818867\nmean concave points     0.829021\narea error              0.875860\nworst radius            0.889125\nworst perimeter         0.878808\nworst area              0.917458\nworst concave points    0.905830\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "uni_roc_auc = ft.univariate_roc_auc(X_train,y_train, X_test, y_test, threshold=0.8)\n",
    "print(uni_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "symmetry error             0.486355\nworst symmetry             0.449074\nsmoothness error           0.447368\ntexture error              0.440789\nfractal dimension error    0.440789\ncompactness error          0.436404\nmean fractal dimension     0.427632\nmean smoothness            0.396503\nworst smoothness           0.389985\nworst texture              0.388158\nconcavity error            0.355263\nmean symmetry              0.346979\nmean texture               0.339912\nworst fractal dimension    0.337719\nconcave points error       0.328947\nmean compactness           0.265351\nworst compactness          0.256579\nradius error               0.239035\nperimeter error            0.219298\nworst concavity            0.197368\nmean perimeter             0.186404\nmean area                  0.184211\nmean concavity             0.168860\nmean concave points        0.162281\nmean radius                0.129386\narea error                 0.128899\nworst perimeter            0.114035\nworst radius               0.108431\nworst concave points       0.089912\nworst area                 0.081140\ndtype: float64\n7  trong 30 feature được giữ lại\nmean fractal dimension     0.427632\ntexture error              0.440789\nsmoothness error           0.447368\ncompactness error          0.436404\nsymmetry error             0.486355\nfractal dimension error    0.440789\nworst symmetry             0.449074\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "uni_mse = ft.univariate_mse(X_train, y_train, X_test, y_test, threshold=0.4)\n",
    "print(uni_mse)"
   ]
  }
 ]
}